"""
å¢—åˆ†ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
post25ã®æ›´æ–°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
"""

import pandas as pd
import sqlite3
from pathlib import Path
from datetime import datetime

# ãƒ‘ã‚¹è¨­å®š
BASE_PATH = Path(__file__).parent.parent
DATABASE_PATH = BASE_PATH / "database" / "analytics.db"
BRONZE_PRE24_PATH = Path("C:/Users/PC/dev/ForStep2/data/Bronze/pre24")
BRONZE_POST25_PATH = Path("C:/Users/PC/dev/ForStep2/data/Bronze/post25")

def print_section(title):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º"""
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}\n")

def load_master_data(source_path, table_name, subfolder, filename):
    """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡æ’é™¤ï¼‰"""
    file_path = source_path / subfolder / filename
    
    if not file_path.exists():
        print(f"  âš  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {filename}")
        return pd.DataFrame()
    
    df = pd.read_csv(file_path)
    print(f"  âœ“ {filename}: {len(df)} ä»¶")
    return df

def merge_master_data(pre_df, post_df, key_columns):
    """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡æ’é™¤ï¼‰"""
    if pre_df.empty:
        return post_df
    if post_df.empty:
        return pre_df
    
    # çµåˆã—ã¦é‡è¤‡æ’é™¤
    combined = pd.concat([pre_df, post_df], ignore_index=True)
    combined = combined.drop_duplicates(subset=key_columns, keep='last')
    
    return combined

def update_dimension_products(conn):
    """è£½å“ãƒã‚¹ã‚¿ãƒ¼æ›´æ–°"""
    print("ğŸ“¦ è£½å“ãƒã‚¹ã‚¿ãƒ¼ (dim_product) æ›´æ–°ä¸­...")
    
    # pre24ã¨post25ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    pre_df = load_master_data(BRONZE_PRE24_PATH, 'dim_product', 'ERP', 'product_master.csv')
    post_df = load_master_data(BRONZE_POST25_PATH, 'dim_product', 'ERP', 'product_master.csv')
    
    # ãƒãƒ¼ã‚¸
    df = merge_master_data(pre_df, post_df, ['product_id'])
    
    if df.empty:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    # ãƒ‡ãƒ¼ã‚¿æ•´å½¢ï¼ˆpost25ã®åˆ—æ§‹é€ ã«å¯¾å¿œï¼‰
    # post25: item_hierarchy(å¤§åˆ†é¡), detail_category(å°åˆ†é¡)ã‚’ä½¿ç”¨
    # ä¾¡æ ¼ãƒ»å˜ä½æƒ…å ±ã¯èª¿é”ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã™ã‚‹ãŸã‚ã€ãƒ€ãƒŸãƒ¼å€¤ã‚’è¨­å®š
    df_dim = pd.DataFrame({
        'product_id': df['product_id'],
        'product_name': df['product_name'],
        'product_category': df['item_hierarchy'] if 'item_hierarchy' in df.columns else df.get('item_group', 'Unknown'),
        'unit_price': 0.0,  # ä¾¡æ ¼æƒ…å ±ã¯èª¿é”ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—
        'unit_of_measure': df.get('base_unit_quantity', 'EA')
    })
    
    df_dim['product_key'] = range(1, len(df_dim) + 1)
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦å†æŒ¿å…¥
    conn.execute("DELETE FROM silver_dim_product")
    df_dim.to_sql('silver_dim_product', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_dim)} ä»¶")
    return len(df_dim)

def update_dimension_locations(conn):
    """æ‹ ç‚¹ãƒã‚¹ã‚¿ãƒ¼æ›´æ–°"""
    print("ğŸ­ æ‹ ç‚¹ãƒã‚¹ã‚¿ãƒ¼ (dim_location) æ›´æ–°ä¸­...")
    
    # è¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿
    sources = [
        ('ERP', 'location_master.csv'),
        ('MES', 'location_master.csv'),
        ('TMS', 'location_master.csv'),
        ('WMS', 'location_master.csv')
    ]
    
    dfs = []
    for source in sources:
        pre_df = load_master_data(BRONZE_PRE24_PATH, 'dim_location', source[0], source[1])
        post_df = load_master_data(BRONZE_POST25_PATH, 'dim_location', source[0], source[1])
        merged = merge_master_data(pre_df, post_df, ['location_id'])
        if not merged.empty:
            dfs.append(merged)
    
    if not dfs:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df = pd.concat(dfs, ignore_index=True)
    df = df.drop_duplicates(subset=['location_id'], keep='last')
    
    df_dim = df[[
        'location_id', 'location_name', 'location_type', 
        'address', 'country'
    ]].copy()
    df_dim['location_key'] = range(1, len(df_dim) + 1)
    
    conn.execute("DELETE FROM dim_location")
    df_dim.to_sql('dim_location', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_dim)} ä»¶")
    return len(df_dim)

def update_dimension_partners(conn):
    """ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ãƒã‚¹ã‚¿ãƒ¼æ›´æ–°"""
    print("ğŸ¤ ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ãƒã‚¹ã‚¿ãƒ¼ (dim_partner) æ›´æ–°ä¸­...")
    
    sources = [
        ('ERP', 'partner_master.csv'),
        ('MES', 'partner_master.csv'),
        ('P2P', 'partner_master.csv'),
        ('TMS', 'partner_master.csv')
    ]
    
    dfs = []
    for source in sources:
        pre_df = load_master_data(BRONZE_PRE24_PATH, 'dim_partner', source[0], source[1])
        post_df = load_master_data(BRONZE_POST25_PATH, 'dim_partner', source[0], source[1])
        merged = merge_master_data(pre_df, post_df, ['partner_id'])
        if not merged.empty:
            dfs.append(merged)
    
    if not dfs:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df = pd.concat(dfs, ignore_index=True)
    df = df.drop_duplicates(subset=['partner_id'], keep='last')
    
    df_dim = df[[
        'partner_id', 'partner_name', 'partner_type', 
        'address', 'country'
    ]].copy()
    df_dim['partner_key'] = range(1, len(df_dim) + 1)
    
    conn.execute("DELETE FROM dim_partner")
    df_dim.to_sql('dim_partner', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_dim)} ä»¶")
    return len(df_dim)

def update_dimension_materials(conn):
    """ææ–™ãƒã‚¹ã‚¿ãƒ¼æ›´æ–°ï¼ˆèª¿é”ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠ½å‡ºï¼‰"""
    print("ğŸ”§ ææ–™ãƒã‚¹ã‚¿ãƒ¼ (dim_material) æ›´æ–°ä¸­...")
    
    dfs = []
    
    # pre24: BOMãƒã‚¹ã‚¿ãƒ¼
    pre_bom = BRONZE_PRE24_PATH / 'P2P' / 'bom_master.csv'
    if pre_bom.exists():
        df = pd.read_csv(pre_bom)
        print(f"  âœ“ pre24 BOMãƒã‚¹ã‚¿ãƒ¼: {len(df)} ä»¶")
        dfs.append(df)
    
    # post25: èª¿é”æ˜ç´°ã‹ã‚‰ææ–™ãƒã‚¹ã‚¿ãƒ¼ã‚’æŠ½å‡º
    post_proc_item = BRONZE_POST25_PATH / 'P2P' / 'procurement_item_post25.csv'
    if post_proc_item.exists():
        df = pd.read_csv(post_proc_item)
        print(f"  âœ“ post25 èª¿é”æ˜ç´°ã‹ã‚‰ææ–™æƒ…å ±æŠ½å‡º: {len(df)} ä»¶")
        
        # ææ–™ãƒã‚¹ã‚¿ãƒ¼æ§‹é€ ã«å¤‰æ›
        df_mat = df[['material_id', 'material_name', 'material_category']].copy()
        df_mat['unit_price'] = df['unit_price_ex_tax']
        df_mat['unit_of_measure'] = 'EA'
        df_mat = df_mat.drop_duplicates(subset=['material_id'], keep='last')
        dfs.append(df_mat)
    
    if not dfs:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df = pd.concat(dfs, ignore_index=True)
    
    # é‡è¤‡æ’é™¤ï¼ˆpost25ã‚’å„ªå…ˆï¼‰
    df = df.drop_duplicates(subset=['material_id'], keep='last')
    
    # å¿…è¦ãªåˆ—ã®ã¿é¸æŠ
    required_cols = ['material_id', 'material_name', 'material_category', 'unit_price', 'unit_of_measure']
    df_dim = df[required_cols].copy()
    df_dim['material_key'] = range(1, len(df_dim) + 1)
    
    conn.execute("DELETE FROM dim_material")
    df_dim.to_sql('dim_material', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_dim)} ä»¶")
    return len(df_dim)

def generate_date_dimension():
    """æ—¥ä»˜ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆ2020-2026ï¼‰"""
    print("ğŸ“… æ—¥ä»˜ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ (dim_date) ç”Ÿæˆä¸­...")
    
    dates = pd.date_range(start='2020-01-01', end='2026-12-31', freq='D')
    
    df_date = pd.DataFrame({
        'date_key': range(1, len(dates) + 1),
        'date': dates.strftime('%Y-%m-%d'),
        'year': dates.year,
        'month': dates.month,
        'day': dates.day,
        'quarter': dates.quarter,
        'year_month': dates.strftime('%Y-%m'),
        'day_of_week': dates.dayofweek + 1,
        'week_of_year': dates.isocalendar().week
    })
    
    print(f"  âœ“ ç”Ÿæˆå®Œäº†: {len(df_date)} ä»¶")
    return df_date

def update_fact_inventory(conn):
    """åœ¨åº«ãƒ•ã‚¡ã‚¯ãƒˆæ›´æ–°"""
    print("ğŸ“Š åœ¨åº«ãƒ•ã‚¡ã‚¯ãƒˆ (fact_inventory) æ›´æ–°ä¸­...")
    
    # pre24: æœˆæ¬¡åœ¨åº« + æœŸæœ«åœ¨åº«
    # post25: æœˆæ¬¡åœ¨åº«ã®ã¿
    
    # pre24ãƒ‡ãƒ¼ã‚¿
    pre_monthly = BRONZE_PRE24_PATH / 'WMS' / 'monthly_inventory_pre24.csv'
    pre_current = BRONZE_PRE24_PATH / 'WMS' / 'current_inventory_dec24.csv'
    
    dfs = []
    
    if pre_monthly.exists():
        df = pd.read_csv(pre_monthly)
        print(f"  âœ“ pre24æœˆæ¬¡åœ¨åº«: {len(df)} ä»¶")
        dfs.append(df)
    
    if pre_current.exists():
        df = pd.read_csv(pre_current)
        print(f"  âœ“ pre24æœŸæœ«åœ¨åº«: {len(df)} ä»¶")
        dfs.append(df)
    
    # post25ãƒ‡ãƒ¼ã‚¿
    post_monthly = BRONZE_POST25_PATH / 'WMS' / 'monthly_inventory_post25.csv'
    if post_monthly.exists():
        df = pd.read_csv(post_monthly)
        print(f"  âœ“ post25æœˆæ¬¡åœ¨åº«: {len(df)} ä»¶")
        dfs.append(df)
    
    if not dfs:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df_inv = pd.concat(dfs, ignore_index=True)
    
    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
    df_products = pd.read_sql("SELECT product_key, product_id FROM dim_product", conn)
    df_locations = pd.read_sql("SELECT location_key, location_id FROM dim_location", conn)
    df_dates = pd.read_sql("SELECT date_key, date FROM dim_date", conn)
    
    df_inv = df_inv.merge(df_products, on='product_id', how='left')
    df_inv = df_inv.merge(df_locations, on='location_id', how='left')
    df_inv = df_inv.merge(df_dates, left_on='snapshot_date', right_on='date', how='left')
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    df_fact = df_inv[[
        'product_key', 'location_key', 'date_key',
        'quantity_on_hand', 'quantity_reserved', 'quantity_available',
        'inventory_value', 'snapshot_date'
    ]].copy()
    
    # æ¬ æå€¤é™¤å»
    df_fact = df_fact.dropna(subset=['product_key', 'location_key', 'date_key'])
    
    # é‡è¤‡æ’é™¤ï¼ˆåŒã˜è£½å“ãƒ»æ‹ ç‚¹ãƒ»æ—¥ä»˜ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
    df_fact = df_fact.drop_duplicates(subset=['product_key', 'location_key', 'date_key'], keep='last')
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦å†æŒ¿å…¥
    conn.execute("DELETE FROM fact_inventory")
    df_fact.to_sql('fact_inventory', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_fact)} ä»¶")
    return len(df_fact)

def update_fact_procurement(conn):
    """èª¿é”ãƒ•ã‚¡ã‚¯ãƒˆæ›´æ–°"""
    print("ğŸ“Š èª¿é”ãƒ•ã‚¡ã‚¯ãƒˆ (fact_procurement) æ›´æ–°ä¸­...")
    
    # pre24ã¨post25ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ»æ˜ç´°ãƒ‡ãƒ¼ã‚¿
    pre_header = BRONZE_PRE24_PATH / 'P2P' / 'procurement_header_pre24.csv'
    pre_item = BRONZE_PRE24_PATH / 'P2P' / 'procurement_item_pre24.csv'
    post_header = BRONZE_POST25_PATH / 'P2P' / 'procurement_header_post25.csv'
    post_item = BRONZE_POST25_PATH / 'P2P' / 'procurement_item_post25.csv'
    
    headers = []
    items = []
    
    if pre_header.exists() and pre_item.exists():
        h = pd.read_csv(pre_header)
        i = pd.read_csv(pre_item)
        print(f"  âœ“ pre24èª¿é”: ãƒ˜ãƒƒãƒ€ãƒ¼{len(h)}ä»¶ã€æ˜ç´°{len(i)}ä»¶")
        headers.append(h)
        items.append(i)
    
    if post_header.exists() and post_item.exists():
        h = pd.read_csv(post_header)
        i = pd.read_csv(post_item)
        print(f"  âœ“ post25èª¿é”: ãƒ˜ãƒƒãƒ€ãƒ¼{len(h)}ä»¶ã€æ˜ç´°{len(i)}ä»¶")
        headers.append(h)
        items.append(i)
    
    if not headers or not items:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df_header = pd.concat(headers, ignore_index=True)
    df_item = pd.concat(items, ignore_index=True)
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã¨æ˜ç´°ã‚’çµåˆ
    df = df_item.merge(
        df_header[['purchase_order_id', 'supplier_id', 'order_date', 'delivery_date', 'status']],
        on='purchase_order_id',
        how='left'
    )
    
    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
    df_materials = pd.read_sql("SELECT material_key, material_id FROM dim_material", conn)
    df_partners = pd.read_sql("SELECT partner_key, partner_id FROM dim_partner", conn)
    df_dates = pd.read_sql("SELECT date_key, date FROM dim_date", conn)
    
    df = df.merge(df_materials, on='material_id', how='left')
    df = df.merge(df_partners, left_on='supplier_id', right_on='partner_id', how='left')
    df['supplier_key'] = df['partner_key']
    df = df.merge(df_dates, left_on='order_date', right_on='date', how='left', suffixes=('', '_order'))
    df['order_date_key'] = df['date_key']
    df = df.merge(df_dates, left_on='delivery_date', right_on='date', how='left', suffixes=('', '_delivery'))
    df['delivery_date_key'] = df['date_key']
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    df_fact = df[[
        'purchase_order_id', 'line_number', 'material_key', 'supplier_key',
        'order_date_key', 'delivery_date_key',
        'quantity', 'unit_price', 'total_amount', 'status'
    ]].copy()
    
    # æ¬ æå€¤é™¤å»
    df_fact = df_fact.dropna(subset=['material_key', 'supplier_key', 'order_date_key'])
    
    # é‡è¤‡æ’é™¤
    df_fact = df_fact.drop_duplicates(subset=['purchase_order_id', 'line_number'], keep='last')
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦å†æŒ¿å…¥
    conn.execute("DELETE FROM fact_procurement")
    df_fact.to_sql('fact_procurement', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_fact)} ä»¶")
    return len(df_fact)

def update_fact_sales(conn):
    """è²©å£²ãƒ•ã‚¡ã‚¯ãƒˆæ›´æ–°"""
    print("ğŸ“Š è²©å£²ãƒ•ã‚¡ã‚¯ãƒˆ (fact_sales_order) æ›´æ–°ä¸­...")
    
    pre_header = BRONZE_PRE24_PATH / 'ERP' / 'sales_order_header_pre24.csv'
    pre_item = BRONZE_PRE24_PATH / 'ERP' / 'sales_order_item_pre24.csv'
    post_header = BRONZE_POST25_PATH / 'ERP' / 'sales_order_header_post25.csv'
    post_item = BRONZE_POST25_PATH / 'ERP' / 'sales_order_item_post25.csv'
    
    headers = []
    items = []
    
    if pre_header.exists() and pre_item.exists():
        h = pd.read_csv(pre_header)
        i = pd.read_csv(pre_item)
        print(f"  âœ“ pre24è²©å£²: ãƒ˜ãƒƒãƒ€ãƒ¼{len(h)}ä»¶ã€æ˜ç´°{len(i)}ä»¶")
        headers.append(h)
        items.append(i)
    
    if post_header.exists() and post_item.exists():
        h = pd.read_csv(post_header)
        i = pd.read_csv(post_item)
        print(f"  âœ“ post25è²©å£²: ãƒ˜ãƒƒãƒ€ãƒ¼{len(h)}ä»¶ã€æ˜ç´°{len(i)}ä»¶")
        headers.append(h)
        items.append(i)
    
    if not headers or not items:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df_header = pd.concat(headers, ignore_index=True)
    df_item = pd.concat(items, ignore_index=True)
    
    df = df_item.merge(
        df_header[['sales_order_id', 'customer_id', 'order_date', 'delivery_date', 'status']],
        on='sales_order_id',
        how='left'
    )
    
    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
    df_products = pd.read_sql("SELECT product_key, product_id FROM dim_product", conn)
    df_partners = pd.read_sql("SELECT partner_key, partner_id FROM dim_partner", conn)
    df_dates = pd.read_sql("SELECT date_key, date FROM dim_date", conn)
    
    df = df.merge(df_products, on='product_id', how='left')
    df = df.merge(df_partners, left_on='customer_id', right_on='partner_id', how='left')
    df['customer_key'] = df['partner_key']
    df = df.merge(df_dates, left_on='order_date', right_on='date', how='left', suffixes=('', '_order'))
    df['order_date_key'] = df['date_key']
    df = df.merge(df_dates, left_on='delivery_date', right_on='date', how='left', suffixes=('', '_delivery'))
    df['delivery_date_key'] = df['date_key']
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    df_fact = df[[
        'sales_order_id', 'line_number', 'product_key', 'customer_key',
        'order_date_key', 'delivery_date_key',
        'quantity', 'unit_price', 'total_amount', 'status'
    ]].copy()
    
    df_fact = df_fact.dropna(subset=['product_key', 'customer_key', 'order_date_key'])
    df_fact = df_fact.drop_duplicates(subset=['sales_order_id', 'line_number'], keep='last')
    
    conn.execute("DELETE FROM fact_sales_order")
    df_fact.to_sql('fact_sales_order', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_fact)} ä»¶")
    return len(df_fact)

def update_fact_shipment(conn):
    """å‡ºè·ãƒ•ã‚¡ã‚¯ãƒˆæ›´æ–°"""
    print("ğŸ“Š å‡ºè·ãƒ•ã‚¡ã‚¯ãƒˆ (fact_shipment) æ›´æ–°ä¸­...")
    
    pre_header = BRONZE_PRE24_PATH / 'MES' / 'shipment_header_pre24.csv'
    pre_item = BRONZE_PRE24_PATH / 'MES' / 'shipment_item_pre24.csv'
    post_header = BRONZE_POST25_PATH / 'MES' / 'shipment_header_post25.csv'
    post_item = BRONZE_POST25_PATH / 'MES' / 'shipment_item_post25.csv'
    
    headers = []
    items = []
    
    if pre_header.exists() and pre_item.exists():
        h = pd.read_csv(pre_header)
        i = pd.read_csv(pre_item)
        print(f"  âœ“ pre24å‡ºè·: ãƒ˜ãƒƒãƒ€ãƒ¼{len(h)}ä»¶ã€æ˜ç´°{len(i)}ä»¶")
        headers.append(h)
        items.append(i)
    
    if post_header.exists() and post_item.exists():
        h = pd.read_csv(post_header)
        i = pd.read_csv(post_item)
        print(f"  âœ“ post25å‡ºè·: ãƒ˜ãƒƒãƒ€ãƒ¼{len(h)}ä»¶ã€æ˜ç´°{len(i)}ä»¶")
        headers.append(h)
        items.append(i)
    
    if not headers or not items:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df_header = pd.concat(headers, ignore_index=True)
    df_item = pd.concat(items, ignore_index=True)
    
    df = df_item.merge(
        df_header[['shipment_id', 'origin_location_id', 'destination_partner_id', 'shipment_date', 'arrival_date', 'status']],
        on='shipment_id',
        how='left'
    )
    
    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
    df_products = pd.read_sql("SELECT product_key, product_id FROM dim_product", conn)
    df_locations = pd.read_sql("SELECT location_key, location_id FROM dim_location", conn)
    df_partners = pd.read_sql("SELECT partner_key, partner_id FROM dim_partner", conn)
    df_dates = pd.read_sql("SELECT date_key, date FROM dim_date", conn)
    
    df = df.merge(df_products, on='product_id', how='left')
    df = df.merge(df_locations, left_on='origin_location_id', right_on='location_id', how='left')
    df['origin_location_key'] = df['location_key']
    df = df.merge(df_partners, left_on='destination_partner_id', right_on='partner_id', how='left')
    df['destination_partner_key'] = df['partner_key']
    df = df.merge(df_dates, left_on='shipment_date', right_on='date', how='left', suffixes=('', '_shipment'))
    df['shipment_date_key'] = df['date_key']
    df = df.merge(df_dates, left_on='arrival_date', right_on='date', how='left', suffixes=('', '_arrival'))
    df['arrival_date_key'] = df['date_key']
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    df_fact = df[[
        'shipment_id', 'line_number', 'product_key', 'origin_location_key',
        'destination_partner_key', 'shipment_date_key', 'arrival_date_key',
        'quantity', 'status'
    ]].copy()
    
    df_fact = df_fact.dropna(subset=['product_key', 'origin_location_key', 'shipment_date_key'])
    df_fact = df_fact.drop_duplicates(subset=['shipment_id', 'line_number'], keep='last')
    
    conn.execute("DELETE FROM fact_shipment")
    df_fact.to_sql('fact_shipment', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_fact)} ä»¶")
    return len(df_fact)

def update_fact_transportation(conn):
    """è¼¸é€ã‚³ã‚¹ãƒˆãƒ•ã‚¡ã‚¯ãƒˆæ›´æ–°"""
    print("ğŸ“Š è¼¸é€ã‚³ã‚¹ãƒˆãƒ•ã‚¡ã‚¯ãƒˆ (fact_transportation_cost) æ›´æ–°ä¸­...")
    
    pre_cost = BRONZE_PRE24_PATH / 'TMS' / 'transportation_cost_pre24.csv'
    post_cost = BRONZE_POST25_PATH / 'TMS' / 'transportation_cost_post25.csv'
    
    dfs = []
    
    if pre_cost.exists():
        df = pd.read_csv(pre_cost)
        print(f"  âœ“ pre24è¼¸é€ã‚³ã‚¹ãƒˆ: {len(df)} ä»¶")
        dfs.append(df)
    
    if post_cost.exists():
        df = pd.read_csv(post_cost)
        print(f"  âœ“ post25è¼¸é€ã‚³ã‚¹ãƒˆ: {len(df)} ä»¶")
        dfs.append(df)
    
    if not dfs:
        print("  âš  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    df_cost = pd.concat(dfs, ignore_index=True)
    
    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
    df_locations = pd.read_sql("SELECT location_key, location_id FROM dim_location", conn)
    df_partners = pd.read_sql("SELECT partner_key, partner_id FROM dim_partner", conn)
    df_dates = pd.read_sql("SELECT date_key, date FROM dim_date", conn)
    
    df_cost = df_cost.merge(df_locations, left_on='origin_location_id', right_on='location_id', how='left')
    df_cost['origin_location_key'] = df_cost['location_key']
    df_cost = df_cost.merge(df_locations, left_on='destination_location_id', right_on='location_id', how='left', suffixes=('', '_dest'))
    df_cost['destination_location_key'] = df_cost['location_key_dest']
    df_cost = df_cost.merge(df_partners, left_on='carrier_id', right_on='partner_id', how='left')
    df_cost['carrier_key'] = df_cost['partner_key']
    df_cost = df_cost.merge(df_dates, left_on='cost_date', right_on='date', how='left')
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    df_fact = df_cost[[
        'shipment_id', 'origin_location_key', 'destination_location_key',
        'carrier_key', 'date_key', 'transportation_cost', 'distance_km', 'cost_date'
    ]].copy()
    
    df_fact = df_fact.dropna(subset=['origin_location_key', 'destination_location_key', 'date_key'])
    df_fact = df_fact.drop_duplicates(subset=['shipment_id'], keep='last')
    
    conn.execute("DELETE FROM fact_transportation_cost")
    df_fact.to_sql('fact_transportation_cost', conn, if_exists='append', index=False)
    
    print(f"  âœ“ æ›´æ–°å®Œäº†: {len(df_fact)} ä»¶")
    return len(df_fact)

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print_section("å¢—åˆ†ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹")
    
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {DATABASE_PATH}")
    print(f"pre24ãƒ‘ã‚¹: {BRONZE_PRE24_PATH}")
    print(f"post25ãƒ‘ã‚¹: {BRONZE_POST25_PATH}")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = sqlite3.connect(str(DATABASE_PATH))
    
    try:
        print_section("ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°")
        
        # è£½å“ãƒã‚¹ã‚¿ãƒ¼
        prod_count = update_dimension_products(conn)
        
        # æ‹ ç‚¹ãƒã‚¹ã‚¿ãƒ¼
        loc_count = update_dimension_locations(conn)
        
        # ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ãƒã‚¹ã‚¿ãƒ¼
        partner_count = update_dimension_partners(conn)
        
        # ææ–™ãƒã‚¹ã‚¿ãƒ¼
        mat_count = update_dimension_materials(conn)
        
        # æ—¥ä»˜ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆå†ç”Ÿæˆï¼‰
        df_date = generate_date_dimension()
        conn.execute("DELETE FROM dim_date")
        df_date.to_sql('dim_date', conn, if_exists='append', index=False)
        
        print_section("ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°")
        
        # åœ¨åº«ãƒ•ã‚¡ã‚¯ãƒˆ
        inv_count = update_fact_inventory(conn)
        
        # èª¿é”ãƒ•ã‚¡ã‚¯ãƒˆ
        proc_count = update_fact_procurement(conn)
        
        # è²©å£²ãƒ•ã‚¡ã‚¯ãƒˆ
        sales_count = update_fact_sales(conn)
        
        # å‡ºè·ãƒ•ã‚¡ã‚¯ãƒˆ
        ship_count = update_fact_shipment(conn)
        
        # è¼¸é€ã‚³ã‚¹ãƒˆãƒ•ã‚¡ã‚¯ãƒˆ
        trans_count = update_fact_transportation(conn)
        
        # ã‚³ãƒŸãƒƒãƒˆ
        conn.commit()
        
        print_section("æ›´æ–°å®Œäº†ã‚µãƒãƒªãƒ¼")
        print("ğŸ“Š ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«:")
        print(f"  - è£½å“: {prod_count} ä»¶")
        print(f"  - æ‹ ç‚¹: {loc_count} ä»¶")
        print(f"  - ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼: {partner_count} ä»¶")
        print(f"  - ææ–™: {mat_count} ä»¶")
        print(f"  - æ—¥ä»˜: {len(df_date)} ä»¶")
        print(f"\nğŸ“ˆ ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«:")
        print(f"  - åœ¨åº«: {inv_count} ä»¶")
        print(f"  - èª¿é”: {proc_count} ä»¶")
        print(f"  - è²©å£²: {sales_count} ä»¶")
        print(f"  - å‡ºè·: {ship_count} ä»¶")
        print(f"  - è¼¸é€ã‚³ã‚¹ãƒˆ: {trans_count} ä»¶")
        
        total_records = inv_count + proc_count + sales_count + ship_count + trans_count
        print(f"\nâœ“ ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,} ä»¶")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        traceback.print_exc()
        conn.rollback()
    finally:
        conn.close()
    
    print_section("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: KPIå†è¨ˆç®—")
    print("æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
    print("  python calculate_gold_kpis.py")

if __name__ == "__main__":
    main()
